{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[WARNING] ME(124501:140138563175232,MainProcess):2023-10-17-23:51:50.934.829 [mindspore/run_check/_check_version.py:102] MindSpore version 2.1.0 and cuda version 11.2.72 does not match, CUDA version [['10.1', '11.1', '11.6']] are supported by MindSpore officially. Please refer to the installation guide for version matching information: https://www.mindspore.cn/install.\n",
                        "/tmp/ipykernel_124501/611030689.py:58: DeprecationWarning: ZZ gate is deprecated, please use Rzz\n",
                        "  encoder += ZZ(f'{0}').on([i, i+1])\n",
                        "/tmp/ipykernel_124501/611030689.py:59: DeprecationWarning: ZZ gate is deprecated, please use Rzz\n",
                        "  encoder += ZZ(f'{0}').on([qubit_num-1, 0])\n",
                        "/tmp/ipykernel_124501/611030689.py:67: DeprecationWarning: ZZ gate is deprecated, please use Rzz\n",
                        "  encoder += ZZ(f'{2}').on([i, i+1])\n",
                        "/tmp/ipykernel_124501/611030689.py:68: DeprecationWarning: ZZ gate is deprecated, please use Rzz\n",
                        "  encoder += ZZ(f'{2}').on([qubit_num-1, 0])\n",
                        "/tmp/ipykernel_124501/611030689.py:76: DeprecationWarning: ZZ gate is deprecated, please use Rzz\n",
                        "  encoder += ZZ(f'{4}').on([i, i+1])\n",
                        "/tmp/ipykernel_124501/611030689.py:77: DeprecationWarning: ZZ gate is deprecated, please use Rzz\n",
                        "  encoder += ZZ(f'{4}').on([qubit_num-1, 0])\n",
                        "/tmp/ipykernel_124501/611030689.py:85: DeprecationWarning: ZZ gate is deprecated, please use Rzz\n",
                        "  encoder += ZZ(f'{6}').on([i, i+1])\n",
                        "/tmp/ipykernel_124501/611030689.py:86: DeprecationWarning: ZZ gate is deprecated, please use Rzz\n",
                        "  encoder += ZZ(f'{6}').on([qubit_num-1, 0])\n",
                        "/tmp/ipykernel_124501/611030689.py:160: DeprecationWarning: ZZ gate is deprecated, please use Rzz\n",
                        "  _circ += ZZ('06').on([bit_up, bit_down])\n",
                        "/tmp/ipykernel_124501/611030689.py:161: DeprecationWarning: YY gate is deprecated, please use Ryy\n",
                        "  _circ += YY('07').on([bit_up, bit_down])\n",
                        "/tmp/ipykernel_124501/611030689.py:162: DeprecationWarning: XX gate is deprecated, please use Rxx\n",
                        "  _circ += XX('08').on([bit_up, bit_down])\n",
                        "[WARNING] ME(124501:140138563175232,MainProcess):2023-10-17-23:51:52.198.484 [mindspore/train/model.py:1098] For StepAcc callback, {'step_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "epoch: 1 step: 1, loss is 0.675919771194458\n",
                        "acc is: 0.47619047619047616\n",
                        "epoch: 1 step: 2, loss is 0.6880807876586914\n",
                        "acc is: 0.5714285714285714\n",
                        "epoch: 1 step: 3, loss is 0.6674663424491882\n",
                        "acc is: 0.47619047619047616\n",
                        "epoch: 1 step: 4, loss is 0.6817567944526672\n",
                        "acc is: 0.47619047619047616\n",
                        "epoch: 1 step: 5, loss is 0.6789175868034363\n",
                        "acc is: 0.5238095238095238\n",
                        "epoch: 1 step: 6, loss is 0.6799542903900146\n",
                        "acc is: 0.5714285714285714\n",
                        "epoch: 1 step: 7, loss is 0.684260368347168\n",
                        "acc is: 0.5714285714285714\n",
                        "epoch: 1 step: 8, loss is 0.6804158091545105\n",
                        "acc is: 0.6666666666666666\n",
                        "epoch: 1 step: 9, loss is 0.6769707798957825\n",
                        "acc is: 0.8095238095238095\n",
                        "epoch: 1 step: 10, loss is 0.6849358081817627\n",
                        "acc is: 0.8571428571428571\n",
                        "epoch: 1 step: 11, loss is 0.6761922836303711\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 1 step: 12, loss is 0.6749659180641174\n",
                        "acc is: 1.0\n",
                        "epoch: 1 step: 13, loss is 0.6836875081062317\n",
                        "acc is: 1.0\n",
                        "epoch: 1 step: 14, loss is 0.6669270396232605\n",
                        "acc is: 1.0\n",
                        "epoch: 1 step: 15, loss is 0.6737134456634521\n",
                        "acc is: 1.0\n",
                        "epoch: 1 step: 16, loss is 0.6833938956260681\n",
                        "acc is: 1.0\n",
                        "epoch: 1 step: 17, loss is 0.6843618750572205\n",
                        "acc is: 1.0\n",
                        "epoch: 1 step: 18, loss is 0.6590715050697327\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 1 step: 19, loss is 0.6726968884468079\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 1 step: 20, loss is 0.6842048764228821\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 2 step: 1, loss is 0.6748721599578857\n",
                        "acc is: 0.8571428571428571\n",
                        "epoch: 2 step: 2, loss is 0.6850684285163879\n",
                        "acc is: 0.8571428571428571\n",
                        "epoch: 2 step: 3, loss is 0.6698777675628662\n",
                        "acc is: 0.8095238095238095\n",
                        "epoch: 2 step: 4, loss is 0.6778535842895508\n",
                        "acc is: 0.8095238095238095\n",
                        "epoch: 2 step: 5, loss is 0.6749992370605469\n",
                        "acc is: 0.8095238095238095\n",
                        "epoch: 2 step: 6, loss is 0.679790198802948\n",
                        "acc is: 0.8095238095238095\n",
                        "epoch: 2 step: 7, loss is 0.6817893981933594\n",
                        "acc is: 0.8095238095238095\n",
                        "epoch: 2 step: 8, loss is 0.6774675250053406\n",
                        "acc is: 0.8095238095238095\n",
                        "epoch: 2 step: 9, loss is 0.6737537980079651\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 2 step: 10, loss is 0.682164192199707\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 2 step: 11, loss is 0.6753694415092468\n",
                        "acc is: 1.0\n",
                        "epoch: 2 step: 12, loss is 0.6741165518760681\n",
                        "acc is: 1.0\n",
                        "epoch: 2 step: 13, loss is 0.6822850704193115\n",
                        "acc is: 1.0\n",
                        "epoch: 2 step: 14, loss is 0.6657225489616394\n",
                        "acc is: 1.0\n",
                        "epoch: 2 step: 15, loss is 0.6717033386230469\n",
                        "acc is: 1.0\n",
                        "epoch: 2 step: 16, loss is 0.6820147633552551\n",
                        "acc is: 1.0\n",
                        "epoch: 2 step: 17, loss is 0.6830475926399231\n",
                        "acc is: 1.0\n",
                        "epoch: 2 step: 18, loss is 0.657415509223938\n",
                        "acc is: 1.0\n",
                        "epoch: 2 step: 19, loss is 0.670630156993866\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 2 step: 20, loss is 0.6826727986335754\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 3 step: 1, loss is 0.6727902293205261\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 3 step: 2, loss is 0.6845459938049316\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 3 step: 3, loss is 0.6682729125022888\n",
                        "acc is: 0.8571428571428571\n",
                        "epoch: 3 step: 4, loss is 0.6757333278656006\n",
                        "acc is: 0.8095238095238095\n",
                        "epoch: 3 step: 5, loss is 0.6728267669677734\n",
                        "acc is: 0.8571428571428571\n",
                        "epoch: 3 step: 6, loss is 0.678398072719574\n",
                        "acc is: 0.8095238095238095\n",
                        "epoch: 3 step: 7, loss is 0.6808376312255859\n",
                        "acc is: 0.8571428571428571\n",
                        "epoch: 3 step: 8, loss is 0.675509512424469\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 3 step: 9, loss is 0.6711547374725342\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 3 step: 10, loss is 0.6796369552612305\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 3 step: 11, loss is 0.6738771796226501\n",
                        "acc is: 1.0\n",
                        "epoch: 3 step: 12, loss is 0.672743558883667\n",
                        "acc is: 1.0\n",
                        "epoch: 3 step: 13, loss is 0.6803080439567566\n",
                        "acc is: 1.0\n",
                        "epoch: 3 step: 14, loss is 0.6637575626373291\n",
                        "acc is: 1.0\n",
                        "epoch: 3 step: 15, loss is 0.6689620018005371\n",
                        "acc is: 1.0\n",
                        "epoch: 3 step: 16, loss is 0.6802918910980225\n",
                        "acc is: 1.0\n",
                        "epoch: 3 step: 17, loss is 0.6812240481376648\n",
                        "acc is: 1.0\n",
                        "epoch: 3 step: 18, loss is 0.6548779010772705\n",
                        "acc is: 1.0\n",
                        "epoch: 3 step: 19, loss is 0.6678796410560608\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 3 step: 20, loss is 0.6804895401000977\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 4 step: 1, loss is 0.6698529720306396\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 4 step: 2, loss is 0.6840092539787292\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 4 step: 3, loss is 0.6656889915466309\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 4 step: 4, loss is 0.6729913353919983\n",
                        "acc is: 0.8571428571428571\n",
                        "epoch: 4 step: 5, loss is 0.6699921488761902\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 4 step: 6, loss is 0.6763536334037781\n",
                        "acc is: 0.8571428571428571\n",
                        "epoch: 4 step: 7, loss is 0.679739236831665\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 4 step: 8, loss is 0.6729621887207031\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 4 step: 9, loss is 0.6676632761955261\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 4 step: 10, loss is 0.6761985421180725\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 4 step: 11, loss is 0.6717211604118347\n",
                        "acc is: 1.0\n",
                        "epoch: 4 step: 12, loss is 0.6708346009254456\n",
                        "acc is: 1.0\n",
                        "epoch: 4 step: 13, loss is 0.6775038838386536\n",
                        "acc is: 1.0\n",
                        "epoch: 4 step: 14, loss is 0.6609106659889221\n",
                        "acc is: 1.0\n",
                        "epoch: 4 step: 15, loss is 0.6651297211647034\n",
                        "acc is: 1.0\n",
                        "epoch: 4 step: 16, loss is 0.677966296672821\n",
                        "acc is: 1.0\n",
                        "epoch: 4 step: 17, loss is 0.6786477565765381\n",
                        "acc is: 1.0\n",
                        "epoch: 4 step: 18, loss is 0.6512608528137207\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 4 step: 19, loss is 0.6640991568565369\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 4 step: 20, loss is 0.6773924827575684\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 5 step: 1, loss is 0.6657776236534119\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 5 step: 2, loss is 0.6834269165992737\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 5 step: 3, loss is 0.6619911789894104\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 5 step: 4, loss is 0.6693618893623352\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 5 step: 5, loss is 0.6662375330924988\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 5 step: 6, loss is 0.6735437512397766\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 5 step: 7, loss is 0.6784220337867737\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 5 step: 8, loss is 0.6696413159370422\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 5 step: 9, loss is 0.6630476117134094\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 5 step: 10, loss is 0.6716363430023193\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 5 step: 11, loss is 0.6688189506530762\n",
                        "acc is: 1.0\n",
                        "epoch: 5 step: 12, loss is 0.6683404445648193\n",
                        "acc is: 1.0\n",
                        "epoch: 5 step: 13, loss is 0.6737920641899109\n",
                        "acc is: 1.0\n",
                        "epoch: 5 step: 14, loss is 0.6571230888366699\n",
                        "acc is: 1.0\n",
                        "epoch: 5 step: 15, loss is 0.6601263880729675\n",
                        "acc is: 1.0\n",
                        "epoch: 5 step: 16, loss is 0.6749825477600098\n",
                        "acc is: 1.0\n",
                        "epoch: 5 step: 17, loss is 0.6753063797950745\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 5 step: 18, loss is 0.6465287804603577\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 5 step: 19, loss is 0.6592291593551636\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 5 step: 20, loss is 0.6734156012535095\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 6 step: 1, loss is 0.6605994701385498\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 6 step: 2, loss is 0.6827580332756042\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 6 step: 3, loss is 0.6572527289390564\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 6 step: 4, loss is 0.6648786067962646\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 6 step: 5, loss is 0.6615921854972839\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 6 step: 6, loss is 0.6700388789176941\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 6 step: 7, loss is 0.6768409609794617\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 6 step: 8, loss is 0.665607750415802\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 6 step: 9, loss is 0.6574215292930603\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 6 step: 10, loss is 0.6661447286605835\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 6 step: 11, loss is 0.6652306914329529\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 6 step: 12, loss is 0.6652808785438538\n",
                        "acc is: 1.0\n",
                        "epoch: 6 step: 13, loss is 0.6693623065948486\n",
                        "acc is: 1.0\n",
                        "epoch: 6 step: 14, loss is 0.652470588684082\n",
                        "acc is: 1.0\n",
                        "epoch: 6 step: 15, loss is 0.6541529893875122\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 6 step: 16, loss is 0.6714277863502502\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 6 step: 17, loss is 0.6713736057281494\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 6 step: 18, loss is 0.6407256126403809\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 6 step: 19, loss is 0.6534314155578613\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 6 step: 20, loss is 0.6688005328178406\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 1, loss is 0.6545408964157104\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 2, loss is 0.681914746761322\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 3, loss is 0.6516051888465881\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 4, loss is 0.6597041487693787\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 5, loss is 0.6561955809593201\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 6, loss is 0.6659324765205383\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 7, loss is 0.6749191284179688\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 8, loss is 0.6610114574432373\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 9, loss is 0.6510202884674072\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 10, loss is 0.6600717902183533\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 7 step: 11, loss is 0.6609591841697693\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 7 step: 12, loss is 0.6615663170814514\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 7 step: 13, loss is 0.6643498539924622\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 7 step: 14, loss is 0.6467772126197815\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 7 step: 15, loss is 0.647308886051178\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 7 step: 16, loss is 0.6674215793609619\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 7 step: 17, loss is 0.6669001579284668\n",
                        "acc is: 0.9523809523809523\n",
                        "epoch: 7 step: 18, loss is 0.6335432529449463\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 19, loss is 0.6469120383262634\n",
                        "acc is: 0.9047619047619048\n",
                        "epoch: 7 step: 20, loss is 0.663632869720459\n",
                        "acc is: 0.9047619047619048\n",
                        "[0.47619047619047616, 0.5714285714285714, 0.47619047619047616, 0.47619047619047616, 0.5238095238095238, 0.5714285714285714, 0.5714285714285714, 0.6666666666666666, 0.8095238095238095, 0.8571428571428571, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9523809523809523, 0.9523809523809523, 0.9047619047619048, 0.8571428571428571, 0.8571428571428571, 0.8095238095238095, 0.8095238095238095, 0.8095238095238095, 0.8095238095238095, 0.8095238095238095, 0.8095238095238095, 0.9047619047619048, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9523809523809523, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.8571428571428571, 0.8095238095238095, 0.8571428571428571, 0.8095238095238095, 0.8571428571428571, 0.9047619047619048, 0.9047619047619048, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9523809523809523, 0.9523809523809523, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.8571428571428571, 0.9047619047619048, 0.8571428571428571, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9523809523809523, 0.9523809523809523, 0.9523809523809523, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9523809523809523, 0.9523809523809523, 0.9523809523809523, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9523809523809523, 0.9523809523809523, 1.0, 1.0, 1.0, 0.9523809523809523, 0.9523809523809523, 0.9523809523809523, 0.9523809523809523, 0.9523809523809523, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048, 0.9523809523809523, 0.9523809523809523, 0.9523809523809523, 0.9523809523809523, 0.9523809523809523, 0.9523809523809523, 0.9523809523809523, 0.9523809523809523, 0.9047619047619048, 0.9047619047619048, 0.9047619047619048]\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# -*- coding: utf-8 -*-\n",
                "\"\"\"\n",
                "Created on Mon Jun 13 17:01:29 2022\n",
                "\n",
                "@author: Waikikilick\n",
                "\"\"\"\n",
                "\n",
                "import os\n",
                "import sys\n",
                "import numpy as np\n",
                "import mindspore as ms\n",
                "from mindquantum import *\n",
                "import mindspore.dataset as ds\n",
                "import matplotlib.pyplot as plt\n",
                "os.environ['OMP_NUM_THREADS'] = '2'\n",
                "import mindspore.context as context\n",
                "from mindspore import Model, load_checkpoint\n",
                "from mindspore.nn import Adam, Accuracy, SoftmaxCrossEntropyWithLogits\n",
                "from mindspore.train.callback import Callback, LossMonitor, ModelCheckpoint, CheckpointConfig\n",
                "\n",
                "ms.context.set_context(mode=ms.context.PYNATIVE_MODE, device_target=\"CPU\") # 训练模式 和 上下文管理器\n",
                "ms.set_seed(1) # 随机数种子\n",
                "np.random.seed(1)\n",
                "\n",
                "class Main():\n",
                "    def __init__(self, batch_size=3): # 定义训练中的批数据大小\n",
                "        super().__init__()\n",
                "        # 导入数据集\n",
                "        self.train_x = np.load('./src/8_train_x.npy', allow_pickle=True)\n",
                "        self.train_y = np.load('./src/8_train_y.npy', allow_pickle=True)\n",
                "        self.eval_x = np.load('./src/8_eval_x.npy', allow_pickle=True)\n",
                "        self.eval_y = np.load('./src/8_eval_y.npy', allow_pickle=True)\n",
                "        self.batch_size = batch_size # 批大小\n",
                "        self.train_dataset = self.build_dataset(self.train_x, self.train_y, self.batch_size) # 构建训练集\n",
                "        self.eval_dataset = self.build_dataset(self.eval_x, self.eval_y, 21) # 构建验证集\n",
                "        self.qnet = MQLayer(self.build_grad_ops()) # 封装网络\n",
                "        self.model = self.build_model() # 建立总模型\n",
                "        self.checkpoint_name = \"./model.ckpt\" # 待保存模型的名字\n",
                "\n",
                "    def build_dataset(self, x, y, batch=None):\n",
                "        train = ds.NumpySlicesDataset(\n",
                "            {  \"image\": x.reshape((x.shape[0], -1)),\n",
                "                \"label\": y.astype(np.int32)\n",
                "            }, shuffle=False) # 因为数据集本来就是随机分布的，所以不用再打乱\n",
                "        if batch is not None:\n",
                "            train = train.batch(batch)\n",
                "        return train\n",
                "\n",
                "    def build_grad_ops(self):\n",
                "        # 构建编码线路\n",
                "        qubit_num = 8\n",
                "        encoder = Circuit()\n",
                "        for i in range(qubit_num):\n",
                "            encoder += H.on(i)\n",
                "        encoder += BarrierGate()\n",
                "\n",
                "        for i in range(qubit_num-1):\n",
                "            encoder += ZZ(f'{0}').on([i, i+1])\n",
                "        encoder += ZZ(f'{0}').on([qubit_num-1, 0])\n",
                "        encoder += BarrierGate()\n",
                "\n",
                "        for i in range(qubit_num):\n",
                "            encoder += RX(f'{1}').on(i)\n",
                "        encoder += BarrierGate()\n",
                "\n",
                "        for i in range(qubit_num-1):\n",
                "            encoder += ZZ(f'{2}').on([i, i+1])\n",
                "        encoder += ZZ(f'{2}').on([qubit_num-1, 0])\n",
                "        encoder += BarrierGate()\n",
                "\n",
                "        for i in range(qubit_num):\n",
                "            encoder += RX(f'{3}').on(i)\n",
                "        encoder += BarrierGate()\n",
                "\n",
                "        for i in range(qubit_num-1):\n",
                "            encoder += ZZ(f'{4}').on([i, i+1])\n",
                "        encoder += ZZ(f'{4}').on([qubit_num-1, 0])\n",
                "        encoder += BarrierGate()\n",
                "\n",
                "        for i in range(qubit_num):\n",
                "            encoder += RX(f'{5}').on(i)\n",
                "        encoder += BarrierGate()\n",
                "\n",
                "        for i in range(qubit_num-1):\n",
                "            encoder += ZZ(f'{6}').on([i, i+1])\n",
                "        encoder += ZZ(f'{6}').on([qubit_num-1, 0])\n",
                "        encoder += BarrierGate()\n",
                "\n",
                "        for i in range(qubit_num):\n",
                "            encoder += RX(f'{7}').on(i)\n",
                "        encoder += BarrierGate()\n",
                "        encoder.no_grad() # 编码线路不参与训练\n",
                "\n",
                "        # 构建拟设线路\n",
                "        ansatz = Circuit()\n",
                "        ansatz += conv_circ('00',0,1)\n",
                "        ansatz += conv_circ('01',2,3)\n",
                "        ansatz += conv_circ('02',4,5)\n",
                "        ansatz += conv_circ('03',6,7)\n",
                "\n",
                "        ansatz += pool_circ('04',0,1)\n",
                "        ansatz += pool_circ('05',3,2)\n",
                "        ansatz += pool_circ('06',4,5)\n",
                "        ansatz += pool_circ('07',7,6)\n",
                "\n",
                "        ansatz += conv_circ('08',1,2)\n",
                "        ansatz += conv_circ('09',5,6)\n",
                "\n",
                "        ansatz += conv_circ('10',2,5)\n",
                "        ansatz += pool_circ('11',2,5)\n",
                "\n",
                "        total_circ = encoder.as_encoder() + ansatz.as_ansatz() # 总线路为 编码线路 + 拟设线路\n",
                "\n",
                "        ham = [Hamiltonian(QubitOperator(f'Z{i}')) for i in [2,5]] # 通过测量第 1,2 个比特的测量值来定义分类结果\n",
                "        sim = Simulator('mqvector', total_circ.n_qubits) # 定义模拟器\n",
                "\n",
                "        grad_ops = sim.get_expectation_with_grad( # 梯度和期望值计算接口\n",
                "            ham,\n",
                "            total_circ,\n",
                "            parallel_worker=5)\n",
                "        return grad_ops\n",
                "\n",
                "    def build_model(self):\n",
                "        self.loss = ms.nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean') # 采用交叉熵损失函数\n",
                "        self.opti = ms.nn.Adam(self.qnet.trainable_params()) # 采用 Adam 优化器\n",
                "        self.model = Model(self.qnet, self.loss, self.opti, metrics={'Acc': Accuracy()}) # 装配模型\n",
                "        return self.model\n",
                "\n",
                "    def train(self, epoch=1): # 训练过程中，每一步都计算一次模型对验证集的预测准确度\n",
                "        self.model.train(epoch, self.train_dataset, callbacks=[LossMonitor(1), acc, ckpoint_cb], dataset_sink_mode=False)\n",
                "\n",
                "    def export_trained_parameters(self): # 输出此时的模型\n",
                "        qnet_weight = self.qnet.weight.asnumpy()\n",
                "        ms.save_checkpoint(self.qnet, self.checkpoint_name)\n",
                "\n",
                "    def load_trained_parameters(self): # 导入指定的模型\n",
                "        ms.load_param_into_net(self.qnet,\n",
                "                               ms.load_checkpoint(self.checkpoint_name))\n",
                "\n",
                "    def load_training_ckpoint(self, ckpoint_name): # 导入训练过程中的某个模型\n",
                "        ms.load_param_into_net(self.qnet,\n",
                "                               ms.load_checkpoint(ckpoint_name))\n",
                "\n",
                "    def predict(self, origin_test_x) -> float: # 用于预测\n",
                "        test_x = origin_test_x.reshape((origin_test_x.shape[0], -1))\n",
                "        predict = self.model.predict(ms.Tensor(test_x))\n",
                "        predict = predict.asnumpy().flatten() > 0\n",
                "        return predict\n",
                "\n",
                "\n",
                "def conv_circ(prefix='0', bit_up=0, bit_down=1): # 定义卷积核\n",
                "    _circ = Circuit()\n",
                "    _circ += RX('00').on(bit_up)\n",
                "    _circ += RY('01').on(bit_up)\n",
                "    _circ += RZ('02').on(bit_up)\n",
                "    _circ += RX('03').on(bit_down)\n",
                "    _circ += RY('04').on(bit_down)\n",
                "    _circ += RZ('05').on(bit_down)\n",
                "\n",
                "    _circ += ZZ('06').on([bit_up, bit_down])\n",
                "    _circ += YY('07').on([bit_up, bit_down])\n",
                "    _circ += XX('08').on([bit_up, bit_down])\n",
                "\n",
                "    _circ += RX('09').on(bit_up)\n",
                "    _circ += RY('10').on(bit_up)\n",
                "    _circ += RZ('11').on(bit_up)\n",
                "    _circ += RX('12').on(bit_down)\n",
                "    _circ += RY('13').on(bit_down)\n",
                "    _circ += RZ('14').on(bit_down)\n",
                "    _circ = add_prefix(_circ, prefix)\n",
                "    return _circ\n",
                "\n",
                "def pool_circ(prefix='0', bit_up=0, bit_down=1): # 定义池化操作\n",
                "    _circ = Circuit()\n",
                "    _circ += RX('00').on(bit_up)\n",
                "    _circ += RY('01').on(bit_up)\n",
                "    _circ += RZ('02').on(bit_up)\n",
                "    _circ += RX('03').on(bit_down)\n",
                "    _circ += RY('04').on(bit_down)\n",
                "    _circ += RZ('05').on(bit_down)\n",
                "\n",
                "    _circ += X.on(bit_down, bit_up)\n",
                "\n",
                "    _circ += RX('06').on(bit_down)\n",
                "    _circ += RY('07').on(bit_down)\n",
                "    _circ += RZ('08').on(bit_down)\n",
                "    _circ = add_prefix(_circ, prefix)\n",
                "    return _circ\n",
                "\n",
                "class StepAcc(Callback):  # 定义一个关于每一步准确率的回调函数\n",
                "    def __init__(self, model):\n",
                "        self.model = model\n",
                "        self.acc = []\n",
                "\n",
                "    def step_end(self, run_context):\n",
                "        acc_tem = self.model.eval(main.eval_dataset, dataset_sink_mode=False)['Acc']\n",
                "        print('acc is:', acc_tem) #, 'lr is:', main.opti.get_lr()[0])\n",
                "        self.acc.append(acc_tem)\n",
                "\n",
                "if __name__ == '__main__':\n",
                "\n",
                "    main = Main()\n",
                "    main.ckpoint_file = './ckpoint_file'\n",
                "\n",
                "    acc = StepAcc(main.model)\n",
                "    config_ck = CheckpointConfig(save_checkpoint_steps=1, keep_checkpoint_max=100000000, exception_save=True)\n",
                "    ckpoint_cb = ModelCheckpoint(prefix='9b', directory=main.ckpoint_file, config=config_ck)\n",
                "    sys.stdout.flush()\n",
                "    epoch =  7\n",
                "    lr = 0.01\n",
                "    main.opti = ms.nn.Adam(main.qnet.trainable_params(), lr)\n",
                "    main.train(epoch) # 训练\n",
                "    print(acc.acc) # 输出训练过程中，验证集分类准确度记录\n",
                "\n",
                "    plt.plot(acc.acc) # 画出训练过程中，验证集分类准确度的变化情况\n",
                "    plt.title('Statistics of accuracy', fontsize=20)\n",
                "    plt.xlabel('Steps', fontsize=20)\n",
                "    plt.ylabel('Accuracy', fontsize=20)\n",
                "    plt.savefig('./src/result_8_qubit')\n",
                "    plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "<table border=\"1\">\n",
                            "  <tr>\n",
                            "    <th>Software</th>\n",
                            "    <th>Version</th>\n",
                            "  </tr>\n",
                            "<tr><td>mindquantum</td><td>0.9.0</td></tr>\n",
                            "<tr><td>mindspore</td><td>2.1.0</td></tr>\n",
                            "<tr>\n",
                            "    <th>System</th>\n",
                            "    <th>Info</th>\n",
                            "</tr>\n",
                            "<tr><td>Python</td><td>3.9.7</td></tr><tr><td>OS</td><td>Linux x86_64</td></tr><tr><td>Memory</td><td>16.71 GB</td></tr><tr><td>CPU Max Thread</td><td>8</td></tr><tr><td>Date</td><td>Tue Oct 17 23:52:07 2023</td></tr>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "<mindquantum.utils.show_info.InfoTable at 0x7f7466b59190>"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from mindquantum.utils.show_info import InfoTable\n",
                "\n",
                "InfoTable('mindquantum', 'mindspore')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "orig_nbformat": 2
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
